{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "### Q1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GUI was created using tkinter. It is relatively simple in structure, with a browse/search bar function to retrieve files, one button for enrollment, one compare and one evaluation. The current build only supports enroll and compare, since other tasks in the assignment were prioritized. \n",
    "\n",
    "Firstly you see the imported libraries, pickle, processing_prints and compare_prints, were as the last two works as the processing filter retrieved from the course notebook: https://github.com/lovellbrian/fingerprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox, filedialog\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pickle\n",
    "import processing_prints\n",
    "import compare_prints\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class FingerprintRecognitionApp cointains initializing of the widgets, and  the action buttons of enrollment and comparing.\n",
    "\n",
    "def enroll_fingerprints(self) uses the process_and_extract_features() to calculate the valid minutiae and local structures, which gets dumped to a pickle file along with the fingerprint image and the filename as a key.\n",
    "\n",
    "When comparing we create a list of enrolled features, which we fill by opening the pickle file and loading every fingerprint. Compare_fingers() is then used to iterate through the list and using the provided comparement functionality to calculate the best possible match. \n",
    "\n",
    "In this state of the build the graphics of processing and comparing is not included. This is due to prioritizing of other tasks in this assignment. But to validate each comparing it is printed out the filename of the best matching score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FingerprintRecognitionApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Fingerprint Recognition System\")\n",
    "\n",
    "        self.enrolled_fingerprints = {}\n",
    "\n",
    "        self.create_widgets()\n",
    "        \n",
    "        # Bind the closing event of the window to the on_closing method\n",
    "        self.root.protocol(\"WM_DELETE_WINDOW\", self.on_closing)\n",
    "\n",
    "    def create_widgets(self):\n",
    "       # Browse Frame\n",
    "        browse_frame = tk.Frame(self.root, padx=10, pady=10)\n",
    "        browse_frame.grid(row=0, column=0, columnspan=2, padx=10, pady=10)\n",
    "\n",
    "        tk.Label(browse_frame, text=\"Select Fingerprint:\").pack(side=tk.LEFT, padx=(0, 5))\n",
    "\n",
    "        self.file_path_entry = tk.Entry(browse_frame, width=50)\n",
    "        self.file_path_entry.pack(side=tk.LEFT, padx=(0, 5))\n",
    "\n",
    "        self.browse_button = tk.Button(browse_frame, text=\"Browse\", command=self.browse_file)\n",
    "        self.browse_button.pack(side=tk.LEFT, padx=(0, 5))\n",
    "\n",
    "        # Enrollment Frame\n",
    "        enrollment_frame = tk.Frame(self.root, padx=10, pady=10)\n",
    "        enrollment_frame.grid(row=1, column=0, padx=10, pady=10)\n",
    "\n",
    "        tk.Label(enrollment_frame, text=\"Enroll Fingerprint:\").grid(row=0, column=0, columnspan=2)\n",
    "\n",
    "        self.enroll_button = tk.Button(enrollment_frame, text=\"Enroll\", command=self.enroll_fingerprint)\n",
    "        self.enroll_button.grid(row=1, column=0, columnspan=2, padx=5, pady=5)\n",
    "\n",
    "        # Comparison Frame\n",
    "        comparison_frame = tk.Frame(self.root, padx=10, pady=10)\n",
    "        comparison_frame.grid(row=1, column=1, padx=10, pady=10)\n",
    "\n",
    "        tk.Label(comparison_frame, text=\"Compare Fingerprint:\").grid(row=0, column=0, columnspan=2)\n",
    "\n",
    "        self.compare_button = tk.Button(comparison_frame, text=\"Compare\", command=self.compare_fingerprint)\n",
    "        self.compare_button.grid(row=1, column=0, padx=5, pady=5)\n",
    "\n",
    "        # Evaluation Frame\n",
    "        evaluation_frame = tk.Frame(self.root, padx=10, pady=10)\n",
    "        evaluation_frame.grid(row=2, column=0, columnspan=2, padx=10, pady=10)\n",
    "\n",
    "        tk.Label(evaluation_frame, text=\"Evaluation:\").grid(row=0, column=0, columnspan=2)\n",
    "\n",
    "        self.evaluate_button = tk.Button(evaluation_frame, text=\"Evaluate\", command=self.evaluate_system)\n",
    "        self.evaluate_button.grid(row=1, column=0, padx=5, pady=5)\n",
    "\n",
    "    def browse_file(self):\n",
    "        file_path = filedialog.askopenfilename()\n",
    "        self.file_path_entry.delete(0, tk.END)\n",
    "        self.file_path_entry.insert(0, file_path)\n",
    "\n",
    "    def enroll_fingerprint(self):\n",
    "        file_path = self.file_path_entry.get()\n",
    "        if file_path:\n",
    "            if file_path in self.enrolled_fingerprints:\n",
    "                messagebox.showerror(\"Error\", \"This fingerprint has already been enrolled.\")\n",
    "            else:\n",
    "                # Call the process_and_extract_features function to process the fingerprint\n",
    "                fingerprint_image, valid_minutiae, local_structures = processing_prints.process_and_extract_features(file_path)\n",
    "\n",
    "                # Store the features in a dictionary\n",
    "                enrolled_features = {\n",
    "                    'filename': os.path.basename(file_path),  # Store only the filename,  # Add file path to the dictionary\n",
    "                    'fingerprint_image': fingerprint_image,\n",
    "                    'valid_minutiae': valid_minutiae,\n",
    "                    'local_structures': local_structures\n",
    "                }\n",
    "\n",
    "                # Save the enrolled features to the pickle file\n",
    "                with open('enrolled_features.pickle', 'ab') as f:\n",
    "                    pickle.dump(enrolled_features, f)\n",
    "\n",
    "                # Add the enrolled fingerprint to the dictionary\n",
    "                self.enrolled_fingerprints[file_path] = enrolled_features\n",
    "\n",
    "                print(\"Enrolled features stored successfully!\")\n",
    "        else:\n",
    "            messagebox.showerror(\"Error\", \"Please select a file for enrollment.\")\n",
    "                    \n",
    "    def compare_fingerprint(self):\n",
    "        file_path = self.file_path_entry.get()\n",
    "        if file_path:\n",
    "            # Load enrolled fingerprints from pickle file\n",
    "            enrolled_fingerprints = []\n",
    "            if os.path.exists('enrolled_features.pickle'):\n",
    "                with open('enrolled_features.pickle', 'rb') as f:\n",
    "                    while True:\n",
    "                        try:\n",
    "                            enrolled_features = pickle.load(f)\n",
    "                            enrolled_fingerprints.append(enrolled_features)\n",
    "                        except EOFError:\n",
    "                            break\n",
    "            \n",
    "            # Process input fingerprint to extract features\n",
    "            f1, m1, ls1 = processing_prints.process_and_extract_features(file_path)\n",
    "\n",
    "            # Compare input features with enrolled features\n",
    "            compare_prints.compare_fingers(file_path, enrolled_fingerprints)\n",
    "        else:\n",
    "            messagebox.showerror(\"Error\", \"Please select a file for comparison.\")\n",
    "\n",
    "    def evaluate_system(self):\n",
    "        # Placeholder function for evaluating system\n",
    "        messagebox.showinfo(\"Evaluate System\", \"System evaluation completed.\")\n",
    "        \n",
    "    # Define a method to gracefully exit the application\n",
    "    def on_closing(self):\n",
    "        # Perform any cleanup tasks here...\n",
    "        self.root.destroy()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see the creation of the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    root = tk.Tk()\n",
    "    app = FingerprintRecognitionApp(root)\n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the file processing_prints.py which is fetches features from the input images and returns fingerprint_image, valid_minutiae, local_structures to either store or use for comparing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "\n",
    "def process_and_extract_features(file_path):\n",
    "    fingerprint = cv.imread(file_path, cv.IMREAD_GRAYSCALE)\n",
    "    if fingerprint is None:\n",
    "        raise ValueError(\"Unable to read the image file. Please check the file path.\")\n",
    "    \n",
    "    # Calculate the local gradient (using Sobel filters)\n",
    "    gx, gy = cv.Sobel(fingerprint, cv.CV_32F, 1, 0), cv.Sobel(fingerprint, cv.CV_32F, 0, 1)\n",
    "    \n",
    "    # Calculate the magnitude of the gradient for each pixel\n",
    "    gx2, gy2 = gx**2, gy**2\n",
    "    gm = np.sqrt(gx2 + gy2)\n",
    "    \n",
    "    # Integral over a square window\n",
    "    sum_gm = cv.boxFilter(gm, -1, (25, 25), normalize=False)\n",
    "    \n",
    "    # Use a simple threshold for segmenting the fingerprint pattern\n",
    "    thr = sum_gm.max() * 0.2\n",
    "    mask = cv.threshold(sum_gm, thr, 255, cv.THRESH_BINARY)[1].astype(np.uint8)\n",
    "    \n",
    "    W = (23, 23)\n",
    "    gxx = cv.boxFilter(gx2, -1, W, normalize=False)\n",
    "    gyy = cv.boxFilter(gy2, -1, W, normalize=False)\n",
    "    gxy = cv.boxFilter(gx * gy, -1, W, normalize=False)\n",
    "    gxx_gyy = gxx - gyy\n",
    "    gxy2 = 2 * gxy\n",
    "\n",
    "    orientations = (cv.phase(gxx_gyy, -gxy2) + np.pi) / 2  # '-' to adjust for y axis direction\n",
    "    sum_gxx_gyy = gxx + gyy\n",
    "    strengths = np.divide(cv.sqrt((gxx_gyy**2 + gxy2**2)), sum_gxx_gyy, out=np.zeros_like(gxx), where=sum_gxx_gyy!=0)\n",
    "    \n",
    "    region = fingerprint[10:90, 80:130]\n",
    "    \n",
    "    # Before computing the x-signature, the region is smoothed to reduce noise\n",
    "    smoothed = cv.blur(region, (5, 5), -1)\n",
    "    xs = np.sum(smoothed, 1)  # The x-signature of the region\n",
    "    \n",
    "    # Find the indices of the x-signature local maxima\n",
    "    local_maxima = np.nonzero(np.r_[False, xs[1:] > xs[:-1]] & np.r_[xs[:-1] >= xs[1:], False])[0]\n",
    "    \n",
    "    # Calculate all the distances between consecutive peaks\n",
    "    distances = local_maxima[1:] - local_maxima[:-1]\n",
    "    \n",
    "    # Estimate the ridge line period as the average of the above distances\n",
    "    ridge_period = np.average(distances)\n",
    "    \n",
    "    # Create the filter bank\n",
    "    or_count = 8\n",
    "    gabor_bank = [gabor_kernel(ridge_period, o) for o in np.arange(0, np.pi, np.pi/or_count)]\n",
    "    \n",
    "    # Filter the whole image with each filter\n",
    "    # Note that the negative image is actually used, to have white ridges on a black background as a result\n",
    "    nf = 255 - fingerprint\n",
    "    all_filtered = np.array([cv.filter2D(nf, cv.CV_32F, f) for f in gabor_bank])\n",
    "    \n",
    "    y_coords, x_coords = np.indices(fingerprint.shape)\n",
    "    # For each pixel, find the index of the closest orientation in the gabor bank\n",
    "    orientation_idx = np.round(((orientations % np.pi) / np.pi) * or_count).astype(np.int32) % or_count\n",
    "    # Take the corresponding convolution result for each pixel, to assemble the final result\n",
    "    filtered = all_filtered[orientation_idx, y_coords, x_coords]\n",
    "    # Convert to grayscale and apply the mask\n",
    "    enhanced = mask & np.clip(filtered, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    # Binarization\n",
    "    _, ridge_lines = cv.threshold(enhanced, 32, 255, cv.THRESH_BINARY)\n",
    "    \n",
    "    # Thinning\n",
    "    skeleton = cv.ximgproc.thinning(ridge_lines, thinningType=cv.ximgproc.THINNING_GUOHALL)\n",
    "    \n",
    "    def compute_crossing_number(values):\n",
    "        return np.count_nonzero(values < np.roll(values, -1))\n",
    "    \n",
    "    # Create a filter that converts any 8-neighborhood into the corresponding byte value [0,255]\n",
    "    cn_filter = np.array([[1, 2, 4],\n",
    "                          [128, 0, 8],\n",
    "                          [64, 32, 16]\n",
    "                          ])\n",
    "    \n",
    "    # Create a lookup table that maps each byte value to the corresponding crossing number\n",
    "    all_8_neighborhoods = [np.array([int(d) for d in f'{x:08b}'])[::-1] for x in range(256)]\n",
    "    cn_lut = np.array([compute_crossing_number(x) for x in all_8_neighborhoods]).astype(np.uint8)\n",
    "    \n",
    "    # Skeleton: from 0/255 to 0/1 values\n",
    "    skeleton01 = np.where(skeleton != 0, 1, 0).astype(np.uint8)\n",
    "    # Apply the filter to encode the 8-neighborhood of each pixel into a byte [0,255] \n",
    "    neighborhood_values = cv.filter2D(skeleton01, -1, cn_filter, borderType=cv.BORDER_CONSTANT)\n",
    "    # Apply the lookup table to obtain the crossing number of each pixel from the byte value of its neighborhood\n",
    "    cn = cv.LUT(neighborhood_values, cn_lut)\n",
    "    # Keep only crossing numbers on the skeleton\n",
    "    cn[skeleton == 0] = 0\n",
    "    \n",
    "    # crossing number == 1 --> Termination, crossing number == 3 --> Bifurcation\n",
    "    minutiae = [(x, y, cn[y, x] == 1) for y, x in zip(*np.where(np.isin(cn, [1, 3])))]\n",
    "    \n",
    "    # A 1-pixel background border is added to the mask before computing the distance transform\n",
    "    mask_distance = cv.distanceTransform(cv.copyMakeBorder(mask, 1, 1, 1, 1, cv.BORDER_CONSTANT), cv.DIST_C, 3)[1:-1, 1:-1]\n",
    "\n",
    "    filtered_minutiae = list(filter(lambda m: mask_distance[m[1], m[0]] > 10, minutiae))\n",
    "    \n",
    "    def compute_next_ridge_following_directions(previous_direction, values):    \n",
    "        next_positions = np.argwhere(values != 0).ravel().tolist()\n",
    "        if len(next_positions) > 0 and previous_direction != 8:\n",
    "            # There is a previous direction: return all the next directions, sorted according to the distance from it,\n",
    "            # except the direction, if any, that corresponds to the previous position\n",
    "            next_positions.sort(key=lambda d: 4 - abs(abs(d - previous_direction) - 4))\n",
    "            if next_positions[-1] == (previous_direction + 4) % 8:  # the direction of the previous position is the opposite one\n",
    "                next_positions = next_positions[:-1]  # removes it\n",
    "        return next_positions\n",
    "    \n",
    "    r2 = 2**0.5  # sqrt(2)\n",
    "\n",
    "    # The eight possible (x, y) offsets with each corresponding Euclidean distance\n",
    "    xy_steps = [(-1, -1, r2), (0, -1, 1), (1, -1, r2), (1, 0, 1), (1, 1, r2), (0, 1, 1), (-1, 1, r2), (-1, 0, 1)]\n",
    "\n",
    "    # LUT: for each 8-neighborhood and each previous direction [0,8], \n",
    "    # where 8 means \"none\", provides the list of possible directions\n",
    "    nd_lut = [[compute_next_ridge_following_directions(pd, x) for pd in range(9)] for x in all_8_neighborhoods]\n",
    "\n",
    "    def follow_ridge_and_compute_angle(x, y, nd_lut, neighborhood_values, cn, xy_steps, d=8):\n",
    "        px, py = x, y\n",
    "        length = 0.0\n",
    "        while length < 20:  # max length followed\n",
    "            next_directions = nd_lut[neighborhood_values[py, px]][d]\n",
    "            if len(next_directions) == 0:\n",
    "                break\n",
    "            # Need to check ALL possible next directions\n",
    "            if (any(cn[py + xy_steps[nd][1], px + xy_steps[nd][0]] != 2 for nd in next_directions)):\n",
    "                break  # another minutia found: we stop here\n",
    "            # Only the first direction has to be followed\n",
    "            d = next_directions[0]\n",
    "            ox, oy, l = xy_steps[d]\n",
    "            px += ox\n",
    "            py += oy\n",
    "            length += l\n",
    "        # check if the minimum length for a valid direction has been reached\n",
    "        return math.atan2(-py + y, px - x) if length >= 10 else None\n",
    "\n",
    "    valid_minutiae = []\n",
    "    for x, y, term in filtered_minutiae:\n",
    "        d = None\n",
    "        if term:  # termination: simply follow and compute the direction        \n",
    "            d = follow_ridge_and_compute_angle(x, y, nd_lut, neighborhood_values, cn, xy_steps)\n",
    "        else:  # bifurcation: follow each of the three branches\n",
    "            dirs = nd_lut[neighborhood_values[y, x]][8]  # 8 means: no previous direction\n",
    "            if len(dirs) == 3:  # only if there are exactly three branches\n",
    "                angles = [follow_ridge_and_compute_angle(x + xy_steps[d][0], y + xy_steps[d][1], nd_lut, neighborhood_values, cn, xy_steps, d) for d in dirs]\n",
    "                if all(a is not None for a in angles):\n",
    "                    a1, a2 = min(((angles[i], angles[(i + 1) % 3]) for i in range(3)), key=lambda t: angle_abs_difference(t[0], t[1]))\n",
    "                    d = angle_mean(a1, a2)\n",
    "        if d is not None:\n",
    "            valid_minutiae.append((x, y, term, d))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Compute the cell coordinates of a generic local structure\n",
    "    mcc_radius = 70\n",
    "    mcc_size = 16\n",
    "\n",
    "    g = 2 * mcc_radius / mcc_size\n",
    "    x = np.arange(mcc_size)*g - (mcc_size/2)*g + g/2\n",
    "    y = x[..., np.newaxis]\n",
    "    iy, ix = np.nonzero(x**2 + y**2 <= mcc_radius**2)\n",
    "    ref_cell_coords = np.column_stack((x[ix], x[iy]))\n",
    "    \n",
    "    mcc_sigma_s = 7.0\n",
    "    mcc_tau_psi = 400.0\n",
    "    mcc_mu_psi = 1e-2\n",
    "\n",
    "    def Gs(t_sqr):\n",
    "        \"\"\"\"Gaussian function with zero mean and mcc_sigma_s standard deviation, see eq. (7) in MCC paper\"\"\"\n",
    "        return np.exp(-0.5 * t_sqr / (mcc_sigma_s**2)) / (math.tau**0.5 * mcc_sigma_s)\n",
    "\n",
    "    def Psi(v):\n",
    "        \"\"\"\"Sigmoid function that limits the contribution of dense minutiae clusters, see eq. (4)-(5) in MCC paper\"\"\"\n",
    "        return 1. / (1. + np.exp(-mcc_tau_psi * (v - mcc_mu_psi)))\n",
    "\n",
    "    \n",
    "    # n: number of minutiae\n",
    "    # c: number of cells in a local structure\n",
    "\n",
    "    xyd = np.array([(x,y,d) for x,y,_,d in valid_minutiae]) # matrix with all minutiae coordinates and directions (n x 3)\n",
    "\n",
    "    # rot: n x 2 x 2 (rotation matrix for each minutia)\n",
    "    d_cos, d_sin = np.cos(xyd[:,2]).reshape((-1,1,1)), np.sin(xyd[:,2]).reshape((-1,1,1))\n",
    "    rot = np.block([[d_cos, d_sin], [-d_sin, d_cos]])\n",
    "\n",
    "    # rot@ref_cell_coords.T : n x 2 x c\n",
    "    # xy : n x 2\n",
    "    xy = xyd[:,:2]\n",
    "    # cell_coords: n x c x 2 (cell coordinates for each local structure)\n",
    "    cell_coords = np.transpose(rot@ref_cell_coords.T + xy[:,:,np.newaxis],[0,2,1])\n",
    "\n",
    "    # cell_coords[:,:,np.newaxis,:]      :  n x c  x 1 x 2\n",
    "    # xy                                 : (1 x 1) x n x 2\n",
    "    # cell_coords[:,:,np.newaxis,:] - xy :  n x c  x n x 2\n",
    "    # dists: n x c x n (for each cell of each local structure, the distance from all minutiae)\n",
    "    dists = np.sum((cell_coords[:,:,np.newaxis,:] - xy)**2, -1)\n",
    "\n",
    "    # cs : n x c x n (the spatial contribution of each minutia to each cell of each local structure)\n",
    "    cs = Gs(dists)\n",
    "    diag_indices = np.arange(cs.shape[0])\n",
    "    cs[diag_indices,:,diag_indices] = 0 # remove the contribution of each minutia to its own cells\n",
    "\n",
    "    # local_structures : n x c (cell values for each local structure)\n",
    "    local_structures = Psi(np.sum(cs, -1))\n",
    "    \n",
    "    f1, m1, ls1 = fingerprint, valid_minutiae, local_structures\n",
    "    \n",
    "    return f1, m1, ls1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we have the compare_fingers() function. We extract local structures from input and pickle file and computes the matrix of all normalized Euclidean distances between local structures in ls1 and ls2. Then the 5 pairs with the smallest distance are used to calculate the comparement score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import processing_prints\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "\n",
    "def compare_fingers(input_file_path, enrolled_features_list):\n",
    "   # Process input fingerprint to extract features\n",
    "    f1, m1, ls1 = processing_prints.process_and_extract_features(input_file_path)\n",
    "\n",
    "    best_match_index = None\n",
    "    best_score = -float('inf')\n",
    "\n",
    "    # Iterate over each set of enrolled features\n",
    "    for idx, enrolled_features in enumerate(enrolled_features_list):\n",
    "        # Extract features\n",
    "        f2 = enrolled_features['fingerprint_image']\n",
    "        m2 = enrolled_features['valid_minutiae']\n",
    "        ls2 = enrolled_features['local_structures']\n",
    "\n",
    "        # Resize ls1 to match the shape of ls2\n",
    "        #ls1_resized = cv.resize(ls1, (ls2.shape[1], ls2.shape[0]))\n",
    "        \n",
    "        dists = np.linalg.norm(ls1[:,np.newaxis,:] - ls2, axis = -1)\n",
    "        dists /= np.linalg.norm(ls1, axis = 1)[:,np.newaxis] + np.linalg.norm(ls2, axis = 1) # Normalize as in eq. (17) of MCC paper\n",
    "        \n",
    "        # Select the num_p pairs with the smallest distances (LSS technique)\n",
    "        num_p = 5 # For simplicity: a fixed number of pairs\n",
    "        pairs = np.unravel_index(np.argpartition(dists, num_p, None)[:num_p], dists.shape)\n",
    "        score = 1 - np.mean(dists[pairs[0], pairs[1]])\n",
    "\n",
    "        # Update best match if needed\n",
    "        if score > best_score:\n",
    "            best_match_index = idx\n",
    "            best_score = score\n",
    "\n",
    "   # Print out the best match score, and filename of the best match\n",
    "    best_match_features = enrolled_features_list[best_match_index]\n",
    "    print(f\"Best match score: {best_score}\")\n",
    "    print(f\"Filename of the best match: {best_match_features['filename']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
